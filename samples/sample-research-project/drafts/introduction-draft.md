---
section: introduction
status: in_progress
word_count: 800
last_modified: 2024-01-19
stepsCompleted: ["problem-statement"]
---

# Introduction and Background

## Problem Statement

Artificial intelligence (AI) and machine learning (ML) are rapidly transforming healthcare delivery, from diagnostic imaging to treatment recommendations to population health management. While these technologies promise improved efficiency and outcomes, their deployment raises profound ethical questions that the healthcare system is only beginning to address.

Recent research has documented significant algorithmic bias in healthcare AI systems. Obermeyer et al. (2019) demonstrated that a widely-used algorithm for identifying high-risk patients systematically underestimated the health needs of Black patients compared to equally sick White patients. This bias affected millions of patients and exemplifies how AI systems can perpetuate and amplify existing healthcare disparities.

The challenge extends beyond bias. Healthcare AI systems operate as "black boxes" whose decision-making processes are often opaque even to their developers. This opacity complicates informed consent, as patients cannot meaningfully consent to interventions they cannot understand. It also raises questions about accountability when AI-assisted decisions lead to adverse outcomes.

Despite growing awareness of these issues, healthcare institutions lack systematic frameworks for evaluating and addressing the ethical implications of AI deployment. Current regulatory structures, designed for traditional medical devices, struggle to accommodate the dynamic, learning nature of AI systems. The result is a patchwork of ad-hoc approaches that leaves patients vulnerable and institutions exposed to unknown risks.

## Research Gap

[Section in progress - to be drafted with Morgan]

Current literature on healthcare AI ethics tends to focus on individual issues—bias, transparency, or accountability—without addressing their interconnections. Few studies examine how these ethical dimensions interact in real-world clinical settings. Moreover, existing research primarily reflects the perspectives of technologists and ethicists, with limited attention to the experiences and concerns of patients and frontline clinicians.

There is also a notable gap between ethical principles and operational guidance. While numerous frameworks articulate what ethical AI should look like, healthcare institutions lack practical tools for translating these principles into organizational policies and clinical workflows.

## Significance

[Section not yet started]

---

## Notes for Next Session

- Need to strengthen research gap with more specific literature citations
- Significance section should connect to funder priorities (NIH emphasis on health equity)
- Consider adding a brief overview of proposed approach at end of introduction
- Morgan has identified 3 additional sources on institutional implementation gaps
